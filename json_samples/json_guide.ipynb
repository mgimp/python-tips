{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with JSON Files through Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON File Example\n",
    "\n",
    "JSON supports primitive types like stirings and numbers, as well as nested lists and objects\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"firstName\": \"Jane\",\n",
    "    \"lastName\": \"Doe\",\n",
    "    \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "    \"age\": 35,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Alice\",\n",
    "            \"age\": 6\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Bob\",\n",
    "            \"age\": 8\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### JSON Vocabulary\n",
    "\n",
    "The process of encoding JSON is usually called serialization. This term refers to the transformation of data into a series of bytes (hence serial) to be stored or transmitted across a network. You may also hear the term marshaling, but that’s a whole other discussion. Naturally, deserialization is the reciprocal process of decoding data that has been stored or delivered in the JSON standard.\n",
    "\n",
    "\n",
    "### Serializing JSON\n",
    "\n",
    "What happens after a computer processes lots of information? It needs to take a data dump. Accordingly, the json library exposes the dump() method for writing data to files. There is also a dumps() method (pronounced as “dump-s”) for writing to a Python string.\n",
    "\n",
    "### Serialization Translations\n",
    "\n",
    "| Python           | JSON   |\n",
    "|------------------|--------|\n",
    "| dict             | object |\n",
    "| list, tuple      | array  |\n",
    "| str              | string |\n",
    "| int, long, float | number |\n",
    "| True             | true   |\n",
    "| False            | false  |\n",
    "| None             | null   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization\n",
    "\n",
    "Suppose you have a python object like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"pokemon\" : {\n",
    "        \"name\" : \"charizard\",\n",
    "        \"type1\" : \"fire\",\n",
    "        \"type2\" : \"flying\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to write the data to a file. Using python's context manager, you can create a file called `save_file.json` and open it in write mode.\n",
    "\n",
    ">`json.dump = dump(obj, fp, *, skipkeys=false, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)`\n",
    ">\n",
    ">Serialize ``obj`` as a JSON formatted stream to ``fp`` (a ``.write()``-supporting file-like object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"save_file.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if you want to continue using the serialized JSON data in the program, you can write it to a native Python `str` object.\n",
    "\n",
    ">`json.dumps = dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)`\n",
    ">\n",
    ">Serialize ``obj`` to a JSON formatted ``str``.\n",
    "\n",
    "Note that you aren't writing to disk here, so no data-like-object will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Keywords\n",
    "\n",
    "`json.dumps(data, indent=4)` | The `indent` keyword argument is used to specify the indentation size for nested structures.\n",
    "\n",
    "`json.dumps(data, separators=(\", \" , \": \"))` | The `separators` keyword argument is used to determine what strings are used to separate and denote key-value pairs. It accepts a 2-tuple which is equal to `(\", \", \": \")` by default (comma for separating key-value pairs, colon for denoting them).\n",
    "\n",
    "More in the [JSON docs](https://docs.python.org/3/library/json.html#basic-usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deserialization\n",
    "\n",
    "Technically, this conversion isn’t a perfect inverse to the serialization table. That basically means that if you encode an object now and then decode it again later, you may not get exactly the same object back.\n",
    "\n",
    "The simplest example would be encoding a tuple and getting back a list after decoding like so:\n",
    "\n",
    "```python\n",
    ">>> blackjack_hand = (8, \"Q\")\n",
    ">>> encoded_hand = json.dumps(blackjack_hand)\n",
    ">>> decoded_hand = json.loads(encoded_hand)\n",
    "\n",
    ">>> blackjack_hand == decoded_hand\n",
    "False\n",
    ">>> type(blackjack_hand)\n",
    "<class 'tuple'>\n",
    ">>> type(decoded_hand)\n",
    "<class 'list'>\n",
    ">>> blackjack_hand == tuple(decoded_hand)\n",
    "True\n",
    "```\n",
    "\n",
    "### Deerialization Translations\n",
    "\n",
    "| JSON          | Python |\n",
    "|---------------|--------|\n",
    "| object        | dict   |\n",
    "| array         | list   |\n",
    "| string        | str    |\n",
    "| number (int)  | int    |\n",
    "| number (real) | float  |\n",
    "| true          | True   |\n",
    "| false         | False  |\n",
    "| null          | None   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, imagine you’ve got some data stored on disk that you’d like to manipulate in memory. You’ll still use the context manager, but this time you’ll open up the existing data_file.json in read mode.\n",
    "\n",
    ">`load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)`\n",
    ">\n",
    ">Deserialize ``fp`` (a ``.read()``-supporting file-like object containing a JSON document) to a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"save_file.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are pretty straightforward here, but keep in mind that the result of this method could return any of the allowed data types from the conversion table. This is only important if you’re loading in data you haven’t seen before. In most cases, the root object will be a dict or a list.\n",
    "\n",
    "If you’ve pulled JSON data in from another program or have otherwise obtained a string of JSON formatted data in Python, you can easily deserialize that with loads(), which naturally loads from a string:\n",
    "\n",
    ">`json.loads = loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)`\n",
    ">\n",
    ">Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance containing a JSON document) to a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = \"\"\"\n",
    "{\n",
    "    \"researcher\": {\n",
    "        \"name\": \"Ford Prefect\",\n",
    "        \"species\": \"Betelgeusian\",\n",
    "        \"relatives\": [\n",
    "            {\n",
    "                \"name\": \"Zaphod Beeblebrox\",\n",
    "                \"species\": \"Betelgeusian\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "data = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real World Example\n",
    "\n",
    "For your introductory example, you’ll use [JSONPlaceholder](https://jsonplaceholder.typicode.com/), a great source of fake JSON data for practice purposes.\n",
    "\n",
    "First create a script file called scratch.py, or whatever you want. I can’t really stop you.\n",
    "\n",
    "You’ll need to make an API request to the JSONPlaceholder service, so just use the [requests](https://docs.python-requests.org/en/master/) package to do the heavy lifting. Add these imports at the top of your file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and make a request to the JSONPlaceholder API for the /todos endpoint. If you’re unfamiliar with requests, there’s actually a handy json() method that will do all of the work for you, but you can practice using the json library to deserialize the text attribute of the response object. It should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n",
    "todos = json.loads(response.text)\n",
    "# print(todos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple users, each with a unique userId, and each task has a Boolean completed property. Can you determine which users have completed the most tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of userId to number of complete TODOs for that user\n",
    "todos_by_user = {}\n",
    "\n",
    "# Increment complete TODOs count for each user.\n",
    "for todo in todos:\n",
    "    if todo[\"completed\"]:\n",
    "        try:\n",
    "            # Increment the existing user's count.\n",
    "            todos_by_user[todo[\"userId\"]] += 1\n",
    "        except KeyError:\n",
    "            # This user has not been seen. Set their count to 1.\n",
    "            todos_by_user[todo[\"userId\"]] = 1\n",
    "\n",
    "# Create a sorted list of (userId, num_complete) pairs.\n",
    "top_users = sorted(todos_by_user.items(), \n",
    "                   key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the maximum number of complete TODOs.\n",
    "max_complete = top_users[0][1]\n",
    "\n",
    "# Create a list of all users who have completed the maximum number of TODOs.\n",
    "users = []\n",
    "for user, num_complete in top_users:\n",
    "    if num_complete < max_complete:\n",
    "        break\n",
    "    users.append(str(user))\n",
    "\n",
    "max_users = \" and \".join(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a list with **completed** todos and write the resultant list to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to filter out completed TODOs of users with max completed TODOS.\n",
    "def keep(todo):\n",
    "    is_complete = todo[\"completed\"]\n",
    "    has_max_count = str(todo[\"userId\"]) in users\n",
    "    return is_complete and has_max_count\n",
    "\n",
    "# Write filtered TODOs to file.\n",
    "with open(\"filtered_data_file.json\", \"w\") as data_file:\n",
    "    filtered_todos = list(filter(keep, todos))\n",
    "    json.dump(filtered_todos, data_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and Decoding Custom Python Objects\n",
    "\n",
    "What happens when we try to serialize the Elf class from that Dungeons & Dragons app you’re working on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elf:\n",
    "    def __init__(self, level, ability_scores=None):\n",
    "        self.level = level\n",
    "        self.ability_scores = {\n",
    "            \"str\": 11, \"dex\": 12, \"con\": 10,\n",
    "            \"int\": 16, \"wis\": 14, \"cha\": 13\n",
    "        } if ability_scores is None else ability_scores\n",
    "        self.hp = 10 + self.ability_scores[\"con\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so surprisingly, Python complains that Elf isn’t serializable.\n",
    "\n",
    "Although the json module can handle most built-in Python types, it doesn’t understand how to encode customized data types by default. It’s like trying to fit a square peg in a round hole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying Data Structures\n",
    "\n",
    "Now, the question is how to deal with more complex data structures. Well, you could try to encode and decode the JSON by hand, but there’s a slightly more clever solution that’ll save you some work. Instead of going straight from the custom data type to JSON, you can throw in an intermediary step.\n",
    "\n",
    "All you need to do is represent your data in terms of the built-in types json already understands. Essentially, you translate the more complex object into a simpler representation, which the json module then translates into JSON. It’s like the transitive property in mathematics: if A = B and B = C, then A = C.\n",
    "\n",
    "## Complex Number Example\n",
    "\n",
    "To get the hang of this, you’ll need a complex object to play with. You could use any custom class you like, but Python has a built-in type called complex for representing complex numbers, and it isn’t serializable by default. So, for the sake of these examples, your complex object is going to be a complex object. Confused yet?\n",
    "\n",
    "```python\n",
    ">>> z = 3 + 8j\n",
    ">>> type(z)\n",
    "# OUT: <class 'complex'>\n",
    ">>> json.dumps(z)\n",
    "# OUT: TypeError: Object of type 'complex' is not JSON serializable\n",
    "```\n",
    "\n",
    "A good question to ask yourself when working with custom types is What is the minimum amount of information necessary to recreate this object? In the case of complex numbers, you only need to know the real and imaginary parts, both of which you can access as attributes on the complex object:\n",
    "\n",
    "```python\n",
    ">>> z.real\n",
    "# OUT: 3.0\n",
    ">>> z.imag\n",
    "# OUT: 8.0\n",
    "```\n",
    "\n",
    "Passing the same numbers into a complex constructor is enough to satisfy the `__eq__` comparison operator:\n",
    "\n",
    "```python\n",
    ">>> complex(3, 8) == z\n",
    "# OUT: True\n",
    "```\n",
    "\n",
    "Breaking custom data types down into their essential components is critical to both the serialization and deserialization processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Custom Types\n",
    "\n",
    "To translate a custom object into JSON, all you need to do is provide an encoding function to the dump() method’s default parameter. The json module will call this function on any objects that aren’t natively serializable. Here’s a simple decoding function you can use for practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_complex(z):\n",
    "    if isinstance(z, complex):\n",
    "        return (z.real, z.imag)\n",
    "    else:\n",
    "        type_name = z.__class__.__name__\n",
    "        raise TypeError(f\"Object of type '{type_name}' is not JSON serializable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you’re expected to raise a `TypeError` if you don’t get the kind of object you were expecting. This way, you avoid accidentally serializing any Elves. Now you can try encoding complex objects for yourself\n",
    "\n",
    "```python\n",
    ">>> json.dumps(9 + 5j, default=encode_complex)\n",
    "# OUT: '[9.0, 5.0]'\n",
    ">>> json.dumps(elf, default=encode_complex)\n",
    "# OUT: TypeError: Object of type 'Elf' is not JSON serializable\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other common approach is to subclass the standard JSONEncoder and override its default() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexEncoder(json.JSONEncoder):\n",
    "    def default(self, z):\n",
    "        if isinstance(z, complex):\n",
    "            return (z.real, z.imag)\n",
    "        else:\n",
    "            return super().default(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of raising the TypeError yourself, you can simply let the base class handle it. You can use this either directly in the dump() method via the cls parameter or by creating an instance of the encoder and calling its encode() method:\n",
    "\n",
    "```python\n",
    ">>> json.dumps(2 + 5j, cls=ComplexEncoder)\n",
    "# OUT: '[2.0, 5.0]'\n",
    "\n",
    ">>> encoder = ComplexEncoder()\n",
    ">>> encoder.encode(3 + 6j)\n",
    "# OUT: '[3.0, 6.0]'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Custom Types\n",
    "\n",
    "While the real and imaginary parts of a complex number are absolutely necessary, they are actually not quite sufficient to recreate the object. This is what happens when you try encoding a complex number with the ComplexEncoder and then decoding the result:\n",
    "\n",
    "```python\n",
    ">>> complex_json = json.dumps(4 + 17j, cls=ComplexEncoder)\n",
    ">>> json.loads(complex_json)\n",
    "# OUT: [4.0, 17.0]\n",
    "```\n",
    "\n",
    "All you get back is a list, and you’d have to pass the values into a complex constructor if you wanted that complex object again. Recall our discussion about teleportation. What’s missing is metadata, or information about the type of data you’re encoding.\n",
    "\n",
    "I suppose the question you really ought ask yourself is What is the minimum amount of information that is both necessary and sufficient to recreate this object?\n",
    "\n",
    "The json module expects all custom types to be expressed as objects in the JSON standard. For variety, you can create a JSON file this time called complex_data.json and add the following object representing a complex number:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"__complex__\": true,\n",
    "    \"real\": 42,\n",
    "    \"imag\": 36\n",
    "}\n",
    "```\n",
    "\n",
    "See the clever bit? That \"__complex__\" key is the metadata we just talked about. It doesn’t really matter what the associated value is. To get this little hack to work, all you need to do is verify that the key exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_complex(dct):\n",
    "    if \"__complex__\" in dct:\n",
    "        return complex(dct[\"real\"], dct[\"imag\"])\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If \"`__complex__`\" isn’t in the dictionary, you can just return the object and let the default decoder deal with it.\n",
    "\n",
    "Every time the load() method attempts to parse an object, you are given the opportunity to intercede before the default decoder has its way with the data. You can do this by passing your decoding function to the object_hook parameter.\n",
    "\n",
    "Now play the same kind of game as before:\n",
    "\n",
    "```python\n",
    ">>> with open(\"complex_data.json\") as complex_data:\n",
    "...     data = complex_data.read()\n",
    "...     z = json.loads(data, object_hook=decode_complex)\n",
    "... \n",
    ">>> type(z)\n",
    "# OUT: <class 'complex'>\n",
    "\n",
    "```\n",
    "\n",
    "While object_hook might feel like the counterpart to the dump() method’s default parameter, the analogy really begins and ends there.\n",
    "\n",
    "This doesn’t just work with one object either. Try putting this list of complex numbers into complex_data.json and running the script again:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"__complex__\":true,\n",
    "    \"real\":42,\n",
    "    \"imag\":36\n",
    "  },\n",
    "  {\n",
    "    \"__complex__\":true,\n",
    "    \"real\":64,\n",
    "    \"imag\":11\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "If all goes well, you’ll get a list of complex objects:\n",
    "\n",
    "```python\n",
    ">>> with open(\"complex_data.json\") as complex_data:\n",
    "...     data = complex_data.read()\n",
    "...     numbers = json.loads(data, object_hook=decode_complex)\n",
    "... \n",
    ">>> numbers\n",
    "# OUT: [(42+36j), (64+11j)]\n",
    "```\n",
    "\n",
    "You could also try subclassing JSONDecoder and overriding object_hook, but it’s better to stick with the lightweight solution whenever possible."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f5ab71bff6db56de884124358177dc4b5f08efc4c8d738c105488aa9e4cf211"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
